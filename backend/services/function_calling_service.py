# ========== IMPORTS ==========
import os
import json
import requests
import feedparser
import pandas as pd
from typing import List, Dict, Optional, Any
from openai import OpenAI
from bs4 import BeautifulSoup
import logging
from tinydb import Query

# Import config v√† database
from config.config import Config
from database import db_manager

# ========== LOGGER SETUP ==========
logger = logging.getLogger(__name__)

# ========== DATABASE INITIALIZATION ==========
data_files_db = db_manager.get_data_files_db()

# ========== CLIENT INITIALIZATION ==========
try:
    client = OpenAI(
        base_url=Config.OPENAI_BASE_URL,
        api_key=Config.OPENAI_API_KEY
    ) if Config.OPENAI_API_KEY else None
except Exception as e:
    logger.error("Vui l√≤ng ƒë·∫£m b·∫£o c√°c bi·∫øn m√¥i tr∆∞·ªùng OPENAI_API_KEY, OPENAI_BASE_URL ƒë√£ ƒë∆∞·ª£c thi·∫øt l·∫≠p.")
    client = None

# ========== FUNCTION CALLING TOOLS ==========

def get_tech_news(query: str = "technology") -> str:
    """L·∫•y tin t·ª©c c√¥ng ngh·ªá m·ªõi nh·∫•t"""
    try:
        feeds = [
            ""
        ]
        
        news_items = []
        for feed_url in feeds:
            try:
                feed = feedparser.parse(feed_url)
                for entry in feed.entries:
                    # L·∫•y th√¥ng tin c∆° b·∫£n t·ª´ RSS
                    news_item = {
                        "title": entry.title,
                        "summary": entry.summary if hasattr(entry, 'summary') else "Kh√¥ng c√≥ t√≥m t·∫Øt",
                        "link": entry.link,
                        "published": entry.published if hasattr(entry, 'published') else "N/A"
                    }
                    
                    # Fetch th√¥ng tin chi ti·∫øt t·ª´ link
                    detailed_content = fetch_article_content(entry.link)
                    if detailed_content:
                        news_item["detailed_content"] = detailed_content
                    
                    news_items.append(news_item)
            except Exception as e:
                logger.error(f"L·ªói khi l·∫•y tin t·ª´ {feed_url}: {e}")
                continue
        
        if news_items:
            result = ""
            for i, item in enumerate(news_items[:10], 1):
                result += f"{i}. **{item['title']}**\n"
                result += f"   üìÖ {item['published']}\n"
                result += f"   üìù {item['summary'][:200]}...\n"
                
                # Th√™m n·ªôi dung chi ti·∫øt n·∫øu c√≥
                if 'detailed_content' in item and item['detailed_content']:
                    result += f"   üì∞ **Chi ti·∫øt:** {item['detailed_content'][:300]}...\n"
                
                result += f"   üîó {item['link']}\n\n"
            return result
        else:
            return "Kh√¥ng th·ªÉ l·∫•y tin t·ª©c l√∫c n√†y. Vui l√≤ng th·ª≠ l·∫°i sau."
            
    except Exception as e:
        return f"L·ªói khi l·∫•y tin t·ª©c: {str(e)}"

def fetch_article_content(url: str) -> str:
    """Fetch n·ªôi dung chi ti·∫øt c·ªßa b√†i b√°o t·ª´ URL"""
    try:
        # Set headers ƒë·ªÉ tr√°nh b·ªã block
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'vi-VN,vi;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
        }
        
        # G·ª≠i request v·ªõi timeout
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        # Parse HTML content
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # T√¨m n·ªôi dung ch√≠nh c·ªßa b√†i b√°o (d√†nh cho VnExpress)
        content_selectors = [
            '.Normal',  # VnExpress article paragraphs
            '.article-content p',  # Generic article content
            '.content p',  # Alternative content selector
            'p'  # Fallback to all paragraphs
        ]
        
        article_text = ""
        for selector in content_selectors:
            paragraphs = soup.select(selector)
            if paragraphs:
                # L·∫•y text t·ª´ c√°c ƒëo·∫°n vƒÉn
                article_text = " ".join([p.get_text().strip() for p in paragraphs[:5]])  # L·∫•y 5 ƒëo·∫°n ƒë·∫ßu
                break
        
        # L√†m s·∫°ch text
        if article_text:
            # Lo·∫°i b·ªè c√°c k√Ω t·ª± kh√¥ng mong mu·ªën
            article_text = article_text.replace('\n', ' ').replace('\r', ' ')
            article_text = ' '.join(article_text.split())  # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng th·ª´a
            
            # Gi·ªõi h·∫°n ƒë·ªô d√†i
            if len(article_text) > 500:
                article_text = article_text[:500] + "..."
                
            return article_text
        
        return ""
        
    except requests.RequestException as e:
        logger.error(f"L·ªói khi fetch URL {url}: {e}")
        return ""
    except Exception as e:
        logger.error(f"L·ªói khi parse content t·ª´ {url}: {e}")
        return ""

def read_data_file(file_path: str) -> str:
    """ƒê·ªçc v√† ph√¢n t√≠ch file d·ªØ li·ªáu"""
    try:
        # Ki·ªÉm tra file c√≥ t·ªìn t·∫°i trong database kh√¥ng
        DataFile = Query()
        file_record = data_files_db.search(DataFile.path == file_path)
        
        if not file_record:
            return f"File '{file_path}' kh√¥ng t·ªìn t·∫°i trong h·ªá th·ªëng."
        
        file_info = file_record[0]
        actual_path = file_info['actual_path']
        
        if not os.path.exists(actual_path):
            return f"File v·∫≠t l√Ω '{actual_path}' kh√¥ng t·ªìn t·∫°i."
        
        # ƒê·ªçc file theo extension
        if actual_path.endswith('.csv'):
            df = pd.read_csv(actual_path)
            result = f"üìä **PH√ÇN T√çCH FILE CSV: {file_path}**\n\n"
            result += f"üî¢ S·ªë d√≤ng: {len(df)}\n"
            result += f"üî¢ S·ªë c·ªôt: {len(df.columns)}\n"
            result += f"üìã C√°c c·ªôt: {', '.join(df.columns.tolist())}\n\n"
            result += "üìà **5 d√≤ng ƒë·∫ßu ti√™n:**\n"
            result += df.head().to_string(index=False)
            result += "\n\nüìä **Th·ªëng k√™ c∆° b·∫£n:**\n"
            result += df.describe().to_string()
            return result
            
        elif actual_path.endswith('.json'):
            with open(actual_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            result = f"üìÑ **PH√ÇN T√çCH FILE JSON: {file_path}**\n\n"
            result += f"üìä Lo·∫°i d·ªØ li·ªáu: {type(data).__name__}\n"
            if isinstance(data, dict):
                result += f"üîë S·ªë keys: {len(data.keys())}\n"
                result += f"üóùÔ∏è Keys: {', '.join(list(data.keys())[:10])}\n"
            elif isinstance(data, list):
                result += f"üìã S·ªë ph·∫ßn t·ª≠: {len(data)}\n"
            result += f"\nüìù **N·ªôi dung (100 k√Ω t·ª± ƒë·∫ßu):**\n{str(data)[:100]}..."
            return result
            
        elif actual_path.endswith('.txt'):
            with open(actual_path, 'r', encoding='utf-8') as f:
                content = f.read()
            result = f"üìÑ **PH√ÇN T√çCH FILE TEXT: {file_path}**\n\n"
            result += f"üìä S·ªë k√Ω t·ª±: {len(content)}\n"
            result += f"üìã S·ªë d√≤ng: {len(content.splitlines())}\n"
            result += f"üìù S·ªë t·ª´: {len(content.split())}\n\n"
            result += f"**N·ªôi dung (500 k√Ω t·ª± ƒë·∫ßu):**\n{content[:500]}..."
            return result
        else:
            return f"ƒê·ªãnh d·∫°ng file '{actual_path.split('.')[-1]}' ch∆∞a ƒë∆∞·ª£c h·ªó tr·ª£."
            
    except Exception as e:
        return f"L·ªói khi ƒë·ªçc file: {str(e)}"

def summarize_information(text: str, summary_type: str = "general") -> str:
    """T·ªïng h·ª£p th√¥ng tin t·ª´ text"""
    try:
        if not client:
            return "OpenAI client ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o."
        
        prompt_templates = {
            "general": "H√£y t√≥m t·∫Øt th√¥ng tin sau m·ªôt c√°ch ng·∫Øn g·ªçn v√† r√µ r√†ng:",
            "technical": "H√£y t√≥m t·∫Øt c√°c th√¥ng tin k·ªπ thu·∫≠t quan tr·ªçng t·ª´ text sau:",
            "news": "H√£y t√≥m t·∫Øt c√°c tin t·ª©c ch√≠nh t·ª´ th√¥ng tin sau:",
            "data": "H√£y ph√¢n t√≠ch v√† t√≥m t·∫Øt d·ªØ li·ªáu t·ª´ th√¥ng tin sau:"
        }
        
        prompt = prompt_templates.get(summary_type, prompt_templates["general"])
        
        response = client.chat.completions.create(
            model=Config.OPENAI_MODEL,
            messages=[
                {"role": "system", "content": "B·∫°n l√† m·ªôt chuy√™n gia t√≥m t·∫Øt th√¥ng tin. H√£y t√≥m t·∫Øt m·ªôt c√°ch ng·∫Øn g·ªçn, ch√≠nh x√°c v√† d·ªÖ hi·ªÉu."},
                {"role": "user", "content": f"{prompt}\n\n{text}"}
            ],
            max_tokens=500,
            temperature=0.3
        )
        
        return f"üìù **T√ìM T·∫ÆT TH√îNG TIN:**\n\n{response.choices[0].message.content}"
        
    except Exception as e:
        return f"L·ªói khi t√≥m t·∫Øt th√¥ng tin: {str(e)}"

# ƒê·ªãnh nghƒ©a c√°c function tools cho OpenAI
function_tools = [
    {
        "type": "function",
        "function": {
            "name": "get_tech_news",
            "description": "L·∫•y tin t·ª©c c√¥ng ngh·ªá m·ªõi nh·∫•t",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "T·ª´ kh√≥a t√¨m ki·∫øm tin t·ª©c (m·∫∑c ƒë·ªãnh: technology)"
                    }
                }
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "read_data_file",
            "description": "ƒê·ªçc v√† ph√¢n t√≠ch file d·ªØ li·ªáu (CSV, JSON, TXT)",
            "parameters": {
                "type": "object",
                "properties": {
                    "file_path": {
                        "type": "string",
                        "description": "ƒê∆∞·ªùng d·∫´n ƒë·∫øn file c·∫ßn ƒë·ªçc"
                    }
                },
                "required": ["file_path"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "summarize_information",
            "description": "T√≥m t·∫Øt th√¥ng tin t·ª´ text",
            "parameters": {
                "type": "object",
                "properties": {
                    "text": {
                        "type": "string",
                        "description": "Text c·∫ßn t√≥m t·∫Øt"
                    },
                    "summary_type": {
                        "type": "string",
                        "enum": ["general", "technical", "news", "data"],
                        "description": "Lo·∫°i t√≥m t·∫Øt"
                    }
                },
                "required": ["text"]
            }
        }
    }
]
